{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1pRoRug-mMsQiW4DMOPJMNiCDFAz3hAnZ","authorship_tag":"ABX9TyMEF6uTsHj6rEPS/ICFSS7Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a2fc0318771a49c984c2dd17518aca21":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34bddc5f42b944fba69898e2b8bf0356","IPY_MODEL_657b85614ceb4f088e5126f624846554","IPY_MODEL_334c5370b9af4616af5531f030cfd5ca"],"layout":"IPY_MODEL_47259e2bb68c4fd8a6756793a201594b"}},"34bddc5f42b944fba69898e2b8bf0356":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f77bb06a9cb1463294c5cd9677a994e7","placeholder":"​","style":"IPY_MODEL_6d92923a033a421ea1ee2a4bdb0ab43c","value":"Map: 100%"}},"657b85614ceb4f088e5126f624846554":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_99d68de4157445cd925fc2b117661f87","max":541369,"min":0,"orientation":"horizontal","style":"IPY_MODEL_15c4cb4ac85e45cc9796b0fd9bbd41da","value":541369}},"334c5370b9af4616af5531f030cfd5ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c52c1e3e315c40bda8f375052aaf7fde","placeholder":"​","style":"IPY_MODEL_43a97d63fda148ac970322e01d7b6665","value":" 541369/541369 [01:31&lt;00:00, 4180.85 examples/s]"}},"47259e2bb68c4fd8a6756793a201594b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f77bb06a9cb1463294c5cd9677a994e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d92923a033a421ea1ee2a4bdb0ab43c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99d68de4157445cd925fc2b117661f87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15c4cb4ac85e45cc9796b0fd9bbd41da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c52c1e3e315c40bda8f375052aaf7fde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43a97d63fda148ac970322e01d7b6665":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75522a8711cf463ebbd09dfd32165803":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b18b0279eb5454abec79dab8cb52892","IPY_MODEL_3be32ff635194ff3bf72ed3b063628de","IPY_MODEL_b602e2049319477d94ef1a6d144f847f"],"layout":"IPY_MODEL_1210bb4db5ec4170bc262f2133a409e2"}},"7b18b0279eb5454abec79dab8cb52892":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20a7109a715b4389bf0bd7f2b63cace2","placeholder":"​","style":"IPY_MODEL_494eb57e76714e3baa3066ceceddd832","value":"Map: 100%"}},"3be32ff635194ff3bf72ed3b063628de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d7104da02a246bbaf9a82e090a46a59","max":59712,"min":0,"orientation":"horizontal","style":"IPY_MODEL_230a57628e994292af9f415c02a94f4c","value":59712}},"b602e2049319477d94ef1a6d144f847f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_747033c8d18d47a185759eb09c9e8cf4","placeholder":"​","style":"IPY_MODEL_4744e640f62a4c5fa289e59de805b401","value":" 59712/59712 [00:09&lt;00:00, 4579.97 examples/s]"}},"1210bb4db5ec4170bc262f2133a409e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20a7109a715b4389bf0bd7f2b63cace2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"494eb57e76714e3baa3066ceceddd832":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d7104da02a246bbaf9a82e090a46a59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"230a57628e994292af9f415c02a94f4c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"747033c8d18d47a185759eb09c9e8cf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4744e640f62a4c5fa289e59de805b401":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df641b247cda4f41865cd2e8758d4abc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dafb5e5cf94541bebabed32591f9f784","IPY_MODEL_f2b62a5851cc49c08f06046dceebc600","IPY_MODEL_fd4a32313bd84ebe9d2aa8cd32db9a45"],"layout":"IPY_MODEL_13d81ee563a740b7a674e5ed6d87584b"}},"dafb5e5cf94541bebabed32591f9f784":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d842818ec7ee4ae3ad7fda961f98741d","placeholder":"​","style":"IPY_MODEL_32ac587be7e547cd961be07511e5188f","value":"Map: 100%"}},"f2b62a5851cc49c08f06046dceebc600":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb88a96473aa4dbc9d32b48170564971","max":14929,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f4aaf19d3334b8d8768f86a601391e2","value":14929}},"fd4a32313bd84ebe9d2aa8cd32db9a45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2709e4cfa1d4dffbcca801133dc4b84","placeholder":"​","style":"IPY_MODEL_2c4998d47196454693820fab5fe006ac","value":" 14929/14929 [00:02&lt;00:00, 6974.25 examples/s]"}},"13d81ee563a740b7a674e5ed6d87584b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d842818ec7ee4ae3ad7fda961f98741d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32ac587be7e547cd961be07511e5188f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb88a96473aa4dbc9d32b48170564971":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f4aaf19d3334b8d8768f86a601391e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2709e4cfa1d4dffbcca801133dc4b84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c4998d47196454693820fab5fe006ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UODigm3xRN2D","executionInfo":{"status":"ok","timestamp":1692633354281,"user_tz":-540,"elapsed":512,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"1d21c73b-a03d-4fd3-f56d-390b2f205aaa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Aug 21 15:55:53 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   66C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oB4SF2DgRRLC","executionInfo":{"status":"ok","timestamp":1692633354281,"user_tz":-540,"elapsed":18,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"5be25929-b20d-4bc4-efc2-9ae3ae853f1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}]},{"cell_type":"code","source":["# change directory\n","\n","%cd /content/drive/MyDrive/ai/competitions/2023_conv_sw_hackathon\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"47nltwHZRXIa","executionInfo":{"status":"ok","timestamp":1692633354281,"user_tz":-540,"elapsed":10,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"dd534030-8901-4ad6-c1a9-6fbbfe1b8835"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ai/competitions/2023_conv_sw_hackathon\n","code\t     data\t       logs\t requirements\n","conversions  __installer__.sh  mlmodels  results\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install --upgrade accelerate==0.20.3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DI0BL2eCRZE4","executionInfo":{"status":"ok","timestamp":1692633387901,"user_tz":-540,"elapsed":33622,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"80aa6ee7-ed3b-4288-ae15-7a88225f00e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: accelerate==0.20.3 in /usr/local/lib/python3.10/dist-packages (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (6.0.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.20.3) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.20.3) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate==0.20.3) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate==0.20.3) (1.3.0)\n"]}]},{"cell_type":"code","source":["!pip install konlpy\n","!pip install mecab-python\n","!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"],"metadata":{"id":"_vdFso51mMgm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","\n","nltk.download(\"popular\")"],"metadata":{"id":"fg9dUyBlVArl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install svgling"],"metadata":{"id":"H3SVxufdYtEe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentence = '아이스 아메리카노는 두 잔 콜드 브루 라떼 한잔이랑 새우깡도 하나 주세요'\n","tokens = nltk.word_tokenize(sentence)\n","tagged = nltk.pos_tag(tokens)\n","entities = nltk.chunk.ne_chunk(tagged)\n","entities"],"metadata":{"id":"4RV2EsB8WV5J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# grammar = \"\"\"\n","# NP: {<DT|PP\\$>?<JJ>*<NN>}\t  # rule 1\n","#   {<NNP>+}                  # rule 2\n","#   {<NNG>+}\n","#   {<NNP|NNG>+}\n","# \"\"\"\n","\n","grammar = \"\"\"\n","NP: {<N.*>*<Suffix>?}   # Noun phrase\n","VP: {<V.*>*}            # Verb phrase\n","AP: {<A.*>*}            # Adjective phrase\n","\"\"\"\n","\n","cp = nltk.RegexpParser(grammar)\n"],"metadata":{"id":"cxtrHMhtYW8K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from konlpy.tag import Mecab\n","\n","mecab = Mecab()\n","mecab.morphs('아이스 아메리카노 두 잔 콜드 브루 라떼 한 잔 주세요')"],"metadata":{"id":"lTNsTXAdSkF6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tagged = mecab.pos(sentence)"],"metadata":{"id":"XN7KeK_um3aL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cp.parse(tagged)"],"metadata":{"id":"sWsD1PCvY7KO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mecab.tagset"],"metadata":{"id":"411oJE8mKHzP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mecab.pos('아이스 아메리카노 두잔이랑 콜드 브루 라떼 한 잔 주세요')"],"metadata":{"id":"TRYySCEwqAvs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mecab.tagset"],"metadata":{"id":"8Q_AYWYwo9zd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","\n","from tqdm.auto import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from datasets import load_dataset\n","from transformers import AutoModel, AutoModelForTokenClassification, AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, Trainer, TrainingArguments\n","\n","from sklearn import preprocessing\n","from sklearn.metrics import f1_score, accuracy_score\n","from sklearn.model_selection import train_test_split\n"],"metadata":{"id":"790i-vWFReRD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_files = ['슈퍼_train.csv', '음식점_train.csv', '식품_train.csv', '카페_train.csv']\n","valid_files = ['슈퍼_validation.csv', '음식점_validation.csv', '식품_validation.csv', '카페_validation.csv']\n","\n","train_dfs = []\n","valid_dfs = []\n","for file in train_files:\n","    df = pd.read_csv(f\"data/라벨링데이터_train/{file}\", low_memory=False)\n","    df = df.dropna(subset=['상품명'], how='any', axis=0)\n","    df.reset_index(drop=True, inplace=True)\n","    train_dfs.append(df)\n","\n","for file in valid_files:\n","    df = pd.read_csv(f\"data/라벨링데이터_validation/{file}\", low_memory=False)\n","    df = df.dropna(subset=['상품명'], how='any', axis=0)\n","    df.reset_index(drop=True, inplace=True)\n","    valid_dfs.append(df)\n","\n","for file in [file for file in os.listdir(\"data/라벨링데이터_train\") if file.endswith(\".csv\")]:\n","    df = pd.read_csv(f\"data/라벨링데이터_train/{file}\", low_memory=False)\n","    df = df.dropna(subset=['상품명'], how='any', axis=0)\n","    df = df[df['수량'].notnull()]\n","    df.reset_index(drop=True, inplace=True)\n","    train_dfs.append(df)\n","\n","for file in [file for file in os.listdir(\"data/라벨링데이터_validation\") if file.endswith(\".csv\")]:\n","    df = pd.read_csv(f\"data/라벨링데이터_validation/{file}\", low_memory=False)\n","    df = df.dropna(subset=['상품명'], how='any', axis=0)\n","    df = df[df['수량'].notnull()]\n","    df.reset_index(drop=True, inplace=True)\n","    valid_dfs.append(df)\n","\n","train_df = pd.concat(train_dfs, ignore_index=True)\n","train_df.drop_duplicates(inplace=True, ignore_index=True)\n","valid_df = pd.concat(valid_dfs, ignore_index=True)\n","valid_df.drop_duplicates(inplace=True, ignore_index=True)"],"metadata":{"id":"WY-lQi0_QCot"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = train_df[['IDX', '발화문', '가격', '수량', '사람', '상품명']]\n","# train_df"],"metadata":{"id":"Z-b82RuWRdO8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_df = valid_df[['IDX', '발화문', '가격', '수량', '사람', '상품명']]\n","# valid_df"],"metadata":{"id":"2NYQro8kReW4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pos_tag_ids = {}\n","pos_tag_ids['UNKNOWN'] = 0\n","for idx, key in enumerate(mecab.tagset.keys()):\n","  pos_tag_ids[key] = idx+1\n","\n","pos_tag_ids"],"metadata":{"id":"tPwbg6IdAyzW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pos_tag_ids['NA'] = len(pos_tag_ids)"],"metadata":{"id":"6VjBdUARM6Sb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ner_tag_ids = {\n","    'O': 0,\n","    'B-MNU': 1,\n","    'I-MNU': 2,\n","    'B-CNT': 3,\n","    'I-CNT': 4\n","}\n","ner_tag_ids"],"metadata":{"id":"qOX6I8A9BcRK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# element -> menu or count (str)\n","def preprocess_element(elements):\n","    if pd.isna(elements):\n","        return []\n","    else:\n","        return list(map(lambda x: x.strip(), elements.split(\"|\")))\n","\n","preprocess_element(\"슈퍼 울트라 아이스 아메리카노| 카푸치노 츄이스티\")"],"metadata":{"id":"9cMOgR3GDloA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def word_to_id_pos(pos_tag):\n","  pos_tag = pos_tag.split(\"+\")\n","  idx = random.randrange(len(pos_tag))\n","  try:\n","    return pos_tag_ids[pos_tag[idx]]\n","  except:\n","    pos_tag_ids[pos_tag[idx]] = len(pos_tag_ids)\n","    return pos_tag_ids[pos_tag[idx]]\n","\n","def word_to_id_ner(ner_tag):\n","  return ner_tag_ids[ner_tag]\n","\n","def tag(df):\n","  id_list = []\n","  tokens_list = []\n","  pos_tags_list = []\n","  chunk_tags_list = []\n","  ner_tags_list = []\n","  for idx in df.index:\n","    sentence = df.loc[idx, '발화문']\n","    menus = list(set(preprocess_element(df.loc[idx, '상품명'])))\n","    counts = list(set(preprocess_element(df.loc[idx, '수량'])))\n","    menus_string = ' '.join(list(set(preprocess_element(df.loc[idx, '상품명']))))\n","    counts_string = ' '.join(list(set(preprocess_element(df.loc[idx, '수량']))))\n","\n","    tagged_words = mecab.pos(sentence)\n","    tokens = []\n","    pos_tags = []\n","    chunk_tags = []\n","    ner_tags = []\n","    for tagged_word in tagged_words:\n","      word, tag = tagged_word\n","      tokens.append(word)\n","      pos_tags.append(word_to_id_pos(tag))\n","      chunk_tags.append(word_to_id_pos(tag))\n","\n","      ner_tag = 0\n","\n","      for menu in menus:\n","        start_idx = menu.find(word)\n","        if start_idx == 0:\n","          ner_tag = 1\n","          break\n","        elif start_idx == -1:\n","          ner_tag = 0\n","        else:\n","          ner_tag = 2\n","          break\n","\n","      if ner_tag == 0:\n","        for count in counts:\n","          start_idx = count.find(word)\n","          if start_idx == 0:\n","            ner_tag = 3\n","            break\n","          elif start_idx == -1:\n","            ner_tag = 0\n","          else:\n","            ner_tag = 4\n","            break\n","\n","      ner_tags.append(ner_tag)\n","\n","    id_list.append(idx)\n","    tokens_list.append(tokens)\n","    pos_tags_list.append(pos_tags)\n","    chunk_tags_list.append(chunk_tags)\n","    ner_tags_list.append(ner_tags)\n","\n","  return pd.DataFrame({\n","      'id': id_list,\n","      'token': tokens_list,\n","      'pos_tag': pos_tags_list,\n","      'chunk_tag': chunk_tags_list,\n","      'ner_tag': ner_tags_list\n","      })\n","\n"],"metadata":{"id":"6uDuvSTI_If6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentence = \"맛밤 10개 주문하려는데 오전 9시까지 배송되나요?\"\n","menus = list(set(preprocess_element(\"맛밤\")))\n","counts = list(set(preprocess_element(\"10개\")))\n","\n","tagged_words = mecab.pos(sentence)\n","tokens = []\n","pos_tags = []\n","chunk_tags = []\n","ner_tags = []\n","for tagged_word in tagged_words:\n","  print(tagged_word)\n","  word, tag = tagged_word\n","  tokens.append(word)\n","  pos_tags.append(word_to_id_pos(tag))\n","  chunk_tags.append(word_to_id_pos(tag))\n","\n","  ner_tag = 0\n","  for count in counts:\n","    print(f\"(count) count: {count}\")\n","    print(f\"(count) word: {word}\")\n","    start_idx = count.find(word)\n","    print(f\"(count) start_idx: {start_idx}\")\n","    print()\n","    if start_idx == 0:\n","      ner_tag = 3\n","      break\n","    elif start_idx == -1:\n","      ner_tag = 0\n","    else:\n","      ner_tag = 4\n","      break\n","\n","  for menu in menus:\n","    start_idx = menu.find(word)\n","    print(f\"(menu) count: {count}\")\n","    print(f\"(menu) word: {word}\")\n","    print(f\"(menu) start_idx: {start_idx}\")\n","    print()\n","    if start_idx == 0:\n","      ner_tag = 1\n","      break\n","    elif start_idx == -1:\n","      ner_tag = 0\n","    else:\n","      ner_tag = 2\n","      break\n","\n","  ner_tags.append(ner_tag)\n"],"metadata":{"id":"NY2iylhY0hD_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def change_count_unit(df):\n","    df = df.copy()\n","    for idx in df.index:\n","        storage_count = df.loc[idx, '수량']\n","        if type(df.loc[idx, '수량']) == str and ' ' not in df.loc[idx, '수량']:\n","            if random.randrange(0,2) == 0:\n","                df.loc[idx, '수량'] = df.loc[idx, '수량'].replace('개', ' 개')\n","\n","        if type(df.loc[idx, '수량']) == str and '개' in df.loc[idx, '수량']:\n","            if random.randrange(0, 10) in (0,1,2,3):\n","                df.loc[idx, '수량'] = df.loc[idx, '수량'].replace('개', '잔')\n","            elif random.randrange(0,10) in (4,5):\n","                df.loc[idx, '수량'] = df.loc[idx, '수량'].replace('개', '조각')\n","            df.loc[idx, '발화문'] = df.loc[idx, '발화문'].replace(storage_count, df.loc[idx, '수량'])\n","\n","    return df"],"metadata":{"id":"zjCnbyXHOWsc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["changed_train_df = change_count_unit(train_df)\n","changed_valid_df = change_count_unit(valid_df)"],"metadata":{"id":"0XIQzq8gOjTU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tagged_train_df = tag(changed_train_df)\n","tagged_valid_df = tag(changed_valid_df)"],"metadata":{"id":"FJQ6gppeP1Zz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tagged_train_df"],"metadata":{"id":"bOpbMVtsAWYH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tagged_valid_df"],"metadata":{"id":"oZglNijDAYEb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tagged_valid_df, tagged_test_df, _, _ = train_test_split(tagged_valid_df, tagged_valid_df['ner_tag'], test_size=0.2, random_state=41)"],"metadata":{"id":"Rb4xY8-qLV30"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tagged_valid_df"],"metadata":{"id":"J_p22UQOOVXY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tagged_test_df"],"metadata":{"id":"ADJfTLdCOY0S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tagged_train_df.to_pickle(\"data/tagged_total_train.pkl\")\n","# tagged_valid_df.to_pickle(\"data/tagged_total_valid.pkl\")\n","# tagged_test_df.to_pickle(\"data/tagged_total_test.pkl\")"],"metadata":{"id":"AwLgtK60QRBQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tagged_train_df.to_json(\"data/tagged_total_train.json\")\n","# tagged_valid_df.to_json(\"data/tagged_total_valid.json\")\n","# tagged_test_df.to_json(\"data/tagged_total_test.json\")"],"metadata":{"id":"qXAC5_KLRhRV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tagged_train_df.to_csv(\"data/tagged_total_train.csv\")\n","tagged_valid_df.to_csv(\"data/tagged_total_valid.csv\")\n","tagged_test_df.to_csv(\"data/tagged_total_test.csv\")"],"metadata":{"id":"LognQ3oTwsWk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","data_files = {\n","    \"train\": \"data/tagged_total_train.csv\",\n","    \"valid\": \"data/tagged_total_valid.csv\",\n","    \"test\": \"data/tagged_total_test.csv\"}\n","raw_datasets = load_dataset(\"csv\", data_files=data_files)\n","raw_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQrx95pZA9aB","executionInfo":{"status":"ok","timestamp":1692633410109,"user_tz":-540,"elapsed":1515,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"c8137741-3d68-4e41-b8cd-13ae1ee11ff7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['Unnamed: 0', 'id', 'token', 'pos_tag', 'chunk_tag', 'ner_tag'],\n","        num_rows: 541369\n","    })\n","    valid: Dataset({\n","        features: ['Unnamed: 0', 'id', 'token', 'pos_tag', 'chunk_tag', 'ner_tag'],\n","        num_rows: 59712\n","    })\n","    test: Dataset({\n","        features: ['Unnamed: 0', 'id', 'token', 'pos_tag', 'chunk_tag', 'ner_tag'],\n","        num_rows: 14929\n","    })\n","})"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["train_datasets = raw_datasets['train']\n","train_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQcUlc5BdpSO","executionInfo":{"status":"ok","timestamp":1692633410110,"user_tz":-540,"elapsed":11,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"62da952a-20df-47be-e535-fea8a396f1ad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['Unnamed: 0', 'id', 'token', 'pos_tag', 'chunk_tag', 'ner_tag'],\n","    num_rows: 541369\n","})"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["import ast\n","# load the dataset and copy the features\n","def process(ex):\n","    return {\n","        \"id\": ex[\"id\"],\n","        \"token\": ast.literal_eval(ex[\"token\"]),\n","        \"pos_tag\": ast.literal_eval(ex[\"pos_tag\"]),\n","        \"chunk_tag\": ast.literal_eval(ex[\"chunk_tag\"]),\n","        \"ner_tag\": ast.literal_eval(ex[\"ner_tag\"])\n","        }\n","raw_datasets = raw_datasets.map(process)"],"metadata":{"id":"c7hpPZdidafS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for split in raw_datasets.keys():\n","    raw_datasets[split] = raw_datasets[split].remove_columns([\"Unnamed: 0\"])\n","    # raw_datasets[split] = raw_datasets[split].remove_columns([\"id\"])"],"metadata":{"id":"gMyEGtQptLpK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["raw_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xI4vKvuQwvs5","executionInfo":{"status":"ok","timestamp":1692633412229,"user_tz":-540,"elapsed":40,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"dfa3c22f-0122-4b69-9ab8-5087b362804b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'token', 'pos_tag', 'chunk_tag', 'ner_tag'],\n","        num_rows: 541369\n","    })\n","    valid: Dataset({\n","        features: ['id', 'token', 'pos_tag', 'chunk_tag', 'ner_tag'],\n","        num_rows: 59712\n","    })\n","    test: Dataset({\n","        features: ['id', 'token', 'pos_tag', 'chunk_tag', 'ner_tag'],\n","        num_rows: 14929\n","    })\n","})"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["raw_datasets['train'][1000]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SD4gPaqL7kpm","executionInfo":{"status":"ok","timestamp":1692633412229,"user_tz":-540,"elapsed":39,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"09927d1c-20d1-45fa-9723-e2507eaceb2f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': 1000,\n"," 'token': ['요즘', '은', '달걀', '한판', '이', '삼', '십', '개', '가', '아니', '네요', '?'],\n"," 'pos_tag': [21, 15, 21, 21, 13, 24, 24, 20, 9, 35, 2, 27],\n"," 'chunk_tag': [21, 15, 21, 21, 13, 24, 24, 20, 9, 35, 2, 27],\n"," 'ner_tag': [0, 0, 1, 0, 0, 3, 4, 4, 0, 0, 0, 0]}"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["ner_feature = raw_datasets['train'].features['ner_tag']\n","ner_feature"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qqk0SmZ-d70s","executionInfo":{"status":"ok","timestamp":1692633412229,"user_tz":-540,"elapsed":30,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"2d956f80-ccc4-43fe-a389-6eee7b9ac47d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["label_names = ['O', 'B-MNU', 'I-MNU', 'B-CNT', 'I-CNT']\n","\n","words = raw_datasets['train'][1000]['token']\n","labels = raw_datasets['train'][1000]['ner_tag']\n","line1 = \"\"\n","line2 = \"\"\n","for word, label in zip(words, labels):\n","  full_label = label_names[label]\n","  max_length = max(len(word), len(full_label))\n","  line1 += word + \" \" * (max_length - len(word) + 1)\n","  line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n","\n","print(line1)\n","print(line2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWTNt_aieRbE","executionInfo":{"status":"ok","timestamp":1692633412229,"user_tz":-540,"elapsed":23,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"a276b3a6-332b-4bd0-e2b4-1984facda2ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["요즘 은 달걀    한판 이 삼     십     개     가 아니 네요 ? \n","O  O B-MNU O  O B-CNT I-CNT I-CNT O O  O  O \n"]}]},{"cell_type":"code","source":["MODEL_NAME = './results/RoBERTa_TokenCl_230821_2/checkpoint-2110'\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","config = AutoConfig.from_pretrained(MODEL_NAME)\n","# config.num_labels = 189\n","model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, config=config, ignore_mismatched_sizes=True)"],"metadata":{"id":"AQX908-uBOKU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.is_fast"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nhwgLUHxMXtF","executionInfo":{"status":"ok","timestamp":1692633427375,"user_tz":-540,"elapsed":33,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"c2efceba-e6ab-4380-84d9-137231c31735"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["inputs = tokenizer(raw_datasets[\"train\"][1000][\"token\"], is_split_into_words=True)\n","inputs.tokens()\n","# inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9rRRSQaoMdPS","executionInfo":{"status":"ok","timestamp":1692633427375,"user_tz":-540,"elapsed":29,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"aa2733c3-0963-4640-9281-c92d13939826"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]',\n"," '요즘',\n"," '은',\n"," '달걀',\n"," '한판',\n"," '이',\n"," '삼',\n"," '십',\n"," '개',\n"," '가',\n"," '아니',\n"," '네요',\n"," '?',\n"," '[SEP]']"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["inputs.word_ids()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4uDXaI07gCTu","executionInfo":{"status":"ok","timestamp":1692633427376,"user_tz":-540,"elapsed":21,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"48716d52-52c4-46e3-c961-8e7a4c8fc573"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, None]"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["def align_labels_with_tokens(labels, word_ids):\n","    new_labels = []\n","    current_word = None\n","    for word_id in word_ids:\n","        if word_id != current_word:\n","            # Start of a new word!\n","            current_word = word_id\n","            label = -100 if word_id is None else labels[word_id]\n","            new_labels.append(label)\n","        elif word_id is None:\n","            # Special token\n","            new_labels.append(-100)\n","        else:\n","            # Same word as previous token\n","            label = labels[word_id]\n","            # If the label is B-XXX we change it to I-XXX\n","            if label % 2 == 1:\n","                label += 1\n","            new_labels.append(label)\n","\n","    return new_labels"],"metadata":{"id":"QdxOXtoxINeC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(\n","        examples[\"token\"], truncation=True, is_split_into_words=True\n","    )\n","    all_labels = examples[\"ner_tag\"]\n","    new_labels = []\n","    for i, labels in enumerate(all_labels):\n","        word_ids = tokenized_inputs.word_ids(i)\n","        new_labels.append(align_labels_with_tokens(labels, word_ids))\n","\n","    tokenized_inputs[\"labels\"] = new_labels\n","    return tokenized_inputs"],"metadata":{"id":"qPk6IXCTMEsI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"],"metadata":{"id":"iNfFwIQHMGKv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_datasets = raw_datasets.map(\n","    tokenize_and_align_labels,\n","    batched=True,\n","    remove_columns=raw_datasets[\"train\"].column_names,\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":197,"referenced_widgets":["a2fc0318771a49c984c2dd17518aca21","34bddc5f42b944fba69898e2b8bf0356","657b85614ceb4f088e5126f624846554","334c5370b9af4616af5531f030cfd5ca","47259e2bb68c4fd8a6756793a201594b","f77bb06a9cb1463294c5cd9677a994e7","6d92923a033a421ea1ee2a4bdb0ab43c","99d68de4157445cd925fc2b117661f87","15c4cb4ac85e45cc9796b0fd9bbd41da","c52c1e3e315c40bda8f375052aaf7fde","43a97d63fda148ac970322e01d7b6665","75522a8711cf463ebbd09dfd32165803","7b18b0279eb5454abec79dab8cb52892","3be32ff635194ff3bf72ed3b063628de","b602e2049319477d94ef1a6d144f847f","1210bb4db5ec4170bc262f2133a409e2","20a7109a715b4389bf0bd7f2b63cace2","494eb57e76714e3baa3066ceceddd832","7d7104da02a246bbaf9a82e090a46a59","230a57628e994292af9f415c02a94f4c","747033c8d18d47a185759eb09c9e8cf4","4744e640f62a4c5fa289e59de805b401","df641b247cda4f41865cd2e8758d4abc","dafb5e5cf94541bebabed32591f9f784","f2b62a5851cc49c08f06046dceebc600","fd4a32313bd84ebe9d2aa8cd32db9a45","13d81ee563a740b7a674e5ed6d87584b","d842818ec7ee4ae3ad7fda961f98741d","32ac587be7e547cd961be07511e5188f","cb88a96473aa4dbc9d32b48170564971","6f4aaf19d3334b8d8768f86a601391e2","d2709e4cfa1d4dffbcca801133dc4b84","2c4998d47196454693820fab5fe006ac"]},"id":"M0C02hogMRR2","executionInfo":{"status":"ok","timestamp":1692633531520,"user_tz":-540,"elapsed":104156,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"a9d5a149-3d16-4d68-b1cd-182a46d992a6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/541369 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2fc0318771a49c984c2dd17518aca21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/59712 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75522a8711cf463ebbd09dfd32165803"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/14929 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df641b247cda4f41865cd2e8758d4abc"}},"metadata":{}}]},{"cell_type":"code","source":["# tokenized_datasets['train'][1000]"],"metadata":{"id":"uikAvp989GeH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# batch = data_collator([tokenized_datasets[\"train\"][i+1000] for i in range(2)])\n","# batch[\"labels\"]"],"metadata":{"id":"fhUTwlG7MJ5Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install seqeval"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u-0U2QiQMO2H","executionInfo":{"status":"ok","timestamp":1692633536182,"user_tz":-540,"elapsed":4669,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"dbb9dd7d-9ccb-453f-bb27-4af0cf4dc768"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n"]}]},{"cell_type":"code","source":["!pip install evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AgrPnpM-hn3p","executionInfo":{"status":"ok","timestamp":1692633547129,"user_tz":-540,"elapsed":10955,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"77fd3b0e-a820-419e-c6db-e14d0cc7913d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.14.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"]}]},{"cell_type":"code","source":["import evaluate\n","\n","metric = evaluate.load(\"seqeval\")"],"metadata":{"id":"vZY_bA8Qhez_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ner_feature = raw_datasets[\"train\"].features[\"ner_tag\"]\n","ner_feature"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZYLzENyViGGY","executionInfo":{"status":"ok","timestamp":1692633549288,"user_tz":-540,"elapsed":15,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"38ddf334-07e6-4585-bbef-523c03e60236"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["label_names = ['O', 'B-MNU', 'I-MNU', 'B-CNT', 'I-CNT']\n","label_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z5KjwwIKiJWc","executionInfo":{"status":"ok","timestamp":1692633549289,"user_tz":-540,"elapsed":13,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"a1ea5ac8-2160-4874-e05f-f340ab1724d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['O', 'B-MNU', 'I-MNU', 'B-CNT', 'I-CNT']"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["labels = raw_datasets['train'][1000]['ner_tag']\n","labels = [label_names[i] for i in labels]\n","print(labels)\n","print(raw_datasets['train'][1000]['ner_tag'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FHUOc3UsdHDq","executionInfo":{"status":"ok","timestamp":1692633549744,"user_tz":-540,"elapsed":460,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"ab09ffa4-12f1-4906-a32a-5b449ab6b640"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['O', 'O', 'B-MNU', 'O', 'O', 'B-CNT', 'I-CNT', 'I-CNT', 'O', 'O', 'O', 'O']\n","[0, 0, 1, 0, 0, 3, 4, 4, 0, 0, 0, 0]\n"]}]},{"cell_type":"code","source":["def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": all_metrics[\"overall_precision\"],\n","        \"recall\": all_metrics[\"overall_recall\"],\n","        \"f1\": all_metrics[\"overall_f1\"],\n","        \"accuracy\": all_metrics[\"overall_accuracy\"],\n","    }"],"metadata":{"id":"xZpkOTLZh-k7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id2label = {i: label for i, label in enumerate(label_names)}\n","label2id = {v: k for k, v in id2label.items()}"],"metadata":{"id":"PO840iKVij_B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id2label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wnzU9wLvitjO","executionInfo":{"status":"ok","timestamp":1692633549745,"user_tz":-540,"elapsed":18,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"a735c9f8-836b-4b89-c764-9f958a50e704"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 'O', 1: 'B-MNU', 2: 'I-MNU', 3: 'B-CNT', 4: 'I-CNT'}"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["label2id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sMM3uhhaivGt","executionInfo":{"status":"ok","timestamp":1692633549745,"user_tz":-540,"elapsed":11,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"faaf0a29-6722-4128-8b6e-2f824d22f7ea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'O': 0, 'B-MNU': 1, 'I-MNU': 2, 'B-CNT': 3, 'I-CNT': 4}"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["model = AutoModelForTokenClassification.from_pretrained(\n","    MODEL_NAME,\n","    id2label=id2label,\n","    label2id=label2id,\n",")"],"metadata":{"id":"HY6sjoboinvd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.config.num_labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-empx2_SivS4","executionInfo":{"status":"ok","timestamp":1692633567397,"user_tz":-540,"elapsed":16,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"42a1bb9d-e84e-4d89-8cb9-e89aec19ec81"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["THE_MODEL = 'RoBERTa_TokenCl_230822_1'\n","OUTPUT_PATH = f'./results/{THE_MODEL}'\n","SUBMISSION_PATH = f'./submission/{THE_MODEL}.csv'\n","PROBS_PATH = f'./submission/{THE_MODEL}_probs.csv'\n","LOG_PATH = f'./logs/{THE_MODEL}'"],"metadata":{"id":"3T9LieOqj0rM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 1\n","TOTAL_BATCH_SIZE = 128\n","BATCH_SIZE = 4\n","GRADIENT_ACCUMULATION = max(TOTAL_BATCH_SIZE // BATCH_SIZE, 1)\n","TOTAL_STEPS = len(raw_datasets['train']) * EPOCHS // TOTAL_BATCH_SIZE\n","LOGGING_STEPS = TOTAL_STEPS // 20\n","SAVE_STEPS = LOGGING_STEPS\n","\n","training_args = TrainingArguments(\n","    output_dir = OUTPUT_PATH,\n","    save_total_limit = 10,\n","    save_steps = SAVE_STEPS,\n","    num_train_epochs = EPOCHS,\n","    learning_rate = 1e-5, #1e-5, 3e-5, #5e-5\n","    per_device_train_batch_size = BATCH_SIZE,\n","    per_device_eval_batch_size = 4,\n","    gradient_accumulation_steps = GRADIENT_ACCUMULATION,\n","    warmup_ratio=0.1,\n","    weight_decay=0.01,\n","    logging_dir=LOG_PATH,\n","    logging_steps=LOGGING_STEPS,\n","    evaluation_strategy='steps',\n","    load_best_model_at_end=True,\n","    fp16=True,\n","    eval_steps=SAVE_STEPS,\n","    metric_for_best_model='f1',\n","    remove_unused_columns=False\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets['train'],\n","    eval_dataset=tokenized_datasets['valid'],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer\n",")\n","\n","trainer.train()\n","\n","model.save_pretrained(OUTPUT_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"HrU-ZlyJWP_t","executionInfo":{"status":"error","timestamp":1692637824768,"user_tz":-540,"elapsed":4257378,"user":{"displayName":"k h","userId":"12913674159121130629"}},"outputId":"9ce2d7f3-0a75-44eb-a6ae-0d5b39efa3b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='711' max='4229' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 711/4229 1:10:34 < 5:50:11, 0.17 it/s, Epoch 0.17/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>211</td>\n","      <td>0.077200</td>\n","      <td>0.081944</td>\n","      <td>0.862463</td>\n","      <td>0.865504</td>\n","      <td>0.863981</td>\n","      <td>0.970640</td>\n","    </tr>\n","    <tr>\n","      <td>422</td>\n","      <td>0.051600</td>\n","      <td>0.095867</td>\n","      <td>0.862247</td>\n","      <td>0.858244</td>\n","      <td>0.860241</td>\n","      <td>0.969769</td>\n","    </tr>\n","    <tr>\n","      <td>633</td>\n","      <td>0.042600</td>\n","      <td>0.097845</td>\n","      <td>0.856151</td>\n","      <td>0.860134</td>\n","      <td>0.858137</td>\n","      <td>0.969545</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<cell line: 39>\u001b[0m:\u001b[94m39\u001b[0m                                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1539\u001b[0m in \u001b[92mtrain\u001b[0m                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1536 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1537 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1538 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1539 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1540 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1541 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1542 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1809\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1806 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_step_begin(args, \u001b[96mself\u001b[0m.state,  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1807 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1808 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.accelerator.accumulate(model):                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1809 \u001b[2m│   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1810 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1811 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1812 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0margs.logging_nan_inf_filter                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2665\u001b[0m in \u001b[92mtraining_step\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2662 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m amp.scale_loss(loss, \u001b[96mself\u001b[0m.optimizer) \u001b[94mas\u001b[0m scaled_loss:                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2663 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mscaled_loss.backward()                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2664 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2665 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.accelerator.backward(loss)                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2666 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2667 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m loss.detach() / \u001b[96mself\u001b[0m.args.gradient_accumulation_steps                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2668 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/accelerate/\u001b[0m\u001b[1;33maccelerator.py\u001b[0m:\u001b[94m1819\u001b[0m in \u001b[92mbackward\u001b[0m               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1816 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mself\u001b[0m.distributed_type == DistributedType.MEGATRON_LM:                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1817 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m                                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1818 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mself\u001b[0m.scaler \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1819 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.scaler.scale(loss).backward(**kwargs)                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1820 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1821 \u001b[0m\u001b[2m│   │   │   \u001b[0mloss.backward(**kwargs)                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1822 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m487\u001b[0m in \u001b[92mbackward\u001b[0m                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/autograd/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m200\u001b[0m in \u001b[92mbackward\u001b[0m               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m200 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run the bac\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine to ru\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mKeyboardInterrupt\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 39&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">39</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1539</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1536 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1537 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1538 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1539 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1540 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1541 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1542 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1809</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1806 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_handler.on_step_begin(args, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1807 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1808 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.accumulate(model):                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1809 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1810 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1811 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1812 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>args.logging_nan_inf_filter                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2665</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_step</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2662 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> amp.scale_loss(loss, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> scaled_loss:                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2663 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>scaled_loss.backward()                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2664 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2665 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.backward(loss)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2666 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2667 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> loss.detach() / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.gradient_accumulation_steps                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2668 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1819</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1816 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.distributed_type == DistributedType.MEGATRON_LM:                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1817 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1818 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1819 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scaler.scale(loss).backward(**kwargs)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1820 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1821 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss.backward(**kwargs)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1822 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">487</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 484 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>create_graph=create_graph,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 485 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 487 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 489 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># The reason we repeat same the comment below is that</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># some Python versions print out the first line of a multi-line function</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># calls in the traceback and some print out the last line</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the bac</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to ru</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"NsNGP8XtYv4F"},"execution_count":null,"outputs":[]}]}